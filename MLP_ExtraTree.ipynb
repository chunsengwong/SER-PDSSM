{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0LjViXfCuwSgzN4+Wa4wo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunsengwong/SER-PDSSM/blob/main/MLP_ExtraTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wLfhJ6R4NJMm"
      },
      "outputs": [],
      "source": [
        "# Let's assume that X is your feature matrix and y are your labels\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observedEmotions = ['sad', 'fearful', 'disgust', 'happy', 'angry']\n",
        "# Load x and y from the saved files\n",
        "\n",
        "with open('/content/x_radvess (540).pkl', 'rb') as f:\n",
        "    x = pickle.load(f)\n",
        "\n",
        "with open('/content/y_radvess (540).pkl', 'rb') as f:\n",
        "    y = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "4eCCylkSNaqk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = MLPClassifier(alpha=1, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,),learning_rate='adaptive', max_iter=1000, random_state=42)\n",
        "\n",
        "# Define the RFE model using ExtraTreesClassifier as the estimator\n",
        "rfe_model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create the RFE object and rank each feature\n",
        "rfe = RFE(estimator=rfe_model, n_features_to_select=147) # Adjust number of features to select\n",
        "\n",
        "# Create a pipeline to combine the steps\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "\n",
        "# Apply standard scaling to the features\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(x, y)\n",
        "\n",
        "# You can check which features have been selected using\n",
        "print(rfe.support_)\n",
        "\n",
        "# And the ranking of the features\n",
        "print(rfe.ranking_)\n",
        "\n",
        "# Transform the data\n",
        "X_transformed = rfe.transform(x)\n",
        "x_train, x_test, y_train, y_test=train_test_split(np.array(X_transformed), y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pKWTdpHOxq3",
        "outputId": "e37fda55-e614-43fa-db3b-6a0465c5d7de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True False  True  True False False  True False\n",
            "  True False False False  True  True  True  True  True  True  True  True\n",
            "  True  True  True False  True False  True  True  True  True False  True\n",
            "  True False False False  True False False  True False False False False\n",
            " False False False False False False False False  True  True  True  True\n",
            "  True  True  True  True  True  True  True False False False False  True\n",
            "  True False False False False False False False False False False  True\n",
            " False False False False  True  True  True  True  True  True False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False  True False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False  True  True  True  True  True  True  True False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False False  True False False False False False False\n",
            " False  True False False False False False  True False False  True False\n",
            " False  True  True False  True  True False False  True  True  True  True\n",
            " False False  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True False False False  True  True False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True False False  True False False False False False False False False\n",
            "  True  True False  True False  True False False False False False False\n",
            " False  True  True False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False  True  True False False  True  True\n",
            "  True False  True False False  True False  True  True False False  True\n",
            " False False False False False False  True False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True False False False False False False False False False  True\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False  True  True  True  True\n",
            " False  True  True False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False  True False False False False False\n",
            " False False False False  True False False  True False False False False\n",
            " False False False False False False False False False False  True False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False  True False  True False False\n",
            " False False False False False False False False False False False False]\n",
            "[  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  23   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1  84   1   1  46   8   1 208\n",
            "   1 128   7  92   1   1   1   1   1   1   1   1   1   1   1  17   1   5\n",
            "   1   1   1   1  64   1   1  14 123  51   1  58  21   1  13  98  72 181\n",
            "  86 113  56   2  53  30 194 132   1   1   1   1   1   1   1   1   1   1\n",
            "   1  62  20  73  36   1   1 107  25 176  52 137 147 340  80  48 180   1\n",
            " 189 186  15 162   1   1   1   1   1   1  81  35 153 216  29  69 102   1\n",
            "  96  74 155 319 240 219  37   3  55   1  45  10  70 122 172 361 277  88\n",
            " 386 385 394 387 383 392 388 391 384 389 393 390 292 173 197  71   1   1\n",
            "   1   1   1   1   1 133 195  97  89 236 170   1   4  59 249 199 328 270\n",
            " 335 108 308 350 229   1 244 116 282 321 222 347  24   1 169 253 245 373\n",
            " 135   1 104 112   1 203 111   1   1 276   1   1 187  67   1   1   1   1\n",
            "  19  28   1   1   1   1   1   1   1   1   1   1   1   1   1   1  50   1\n",
            " 302 298 337   1   1 286 119 124 259 120 211  16 357 221 243 185 300 354\n",
            " 247 367 224 228 192  77 149 378 202 125 278 374 205   1   1  26  75 179\n",
            " 136 139  27  93 257 150   1 254 145   1 148 184 117  43 371 324 284  49\n",
            "   1   1  83   1  44   1  11 127 314 271 165 318 118   1   1 214 126 239\n",
            " 330 344 375  47 353 246 109  82 339  66 242 322 377 304 256 115 331 369\n",
            " 332 160 141 225 215 263 178 297  38  18 171 154 218  40 248 315  94 175\n",
            "   1   1 129 143   1   1   1  95   1  41 252   1  78   1   1  42  32   1\n",
            "   6 235 269 167 255 206   1 163 106 368 156 362 232 138 157 174 131 303\n",
            " 200 333 341 359 261 258 275   1 110 381 301  90 279 130 151 193 281   1\n",
            "  31 309 293 349 295 230 336  57 220 325 352 251 296 306 294 144 372 329\n",
            " 210 103   1   1   1   1  61   1   1 101 158 213 272 379 313   1 209 142\n",
            " 226 238 289 343 370 288 166 287 183 264  65 161 188 345 346 196 326 223\n",
            " 366 334 290 250 198 273 140 234 100 376  34 201 191 268  87 212 291 327\n",
            " 320 134  91  79 363 310   1 114  12 233 152 262  54  68  99 164   1 231\n",
            "  22   1 274 121 207 355 146  76 190 217 266 317 312 241 265  33   1 283\n",
            " 159 311 280 365 342 338 316 380 237 360  39  63 299 260  60   9 177  85\n",
            " 105   1 285   1 182 168 356 323 351 348 307 364 358 382 267 204 305 227]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train)\n",
        "print((x_train.shape[0], x_test.shape[0]))\n",
        "print(f'Features extracted:{x_train.shape[1]}')\n",
        "\n",
        "y_pred=model.predict(x_test)\n",
        "accuracy= accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=observedEmotions, output_dict=True)\n",
        "weighted_precision = report['weighted avg']['precision']\n",
        "weighted_recall = report['weighted avg']['recall']\n",
        "weighted_f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print(\"Weighted Precision: {:.2f}%\".format(weighted_precision*100))\n",
        "print(\"Weighted Recall: {:.2f}%\".format(weighted_recall*100))\n",
        "print(\"Weighted F1-score: {:.2f}%\".format(weighted_f1_score*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyfAIZ6WQSfS",
        "outputId": "0a929185-c15a-4f0e-eee6-e198e208a386"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(717, 240)\n",
            "Features extracted:147\n",
            "Accuracy: 86.25%\n",
            "Weighted Precision: 86.62%\n",
            "Weighted Recall: 86.25%\n",
            "Weighted F1-score: 86.27%\n"
          ]
        }
      ]
    }
  ]
}